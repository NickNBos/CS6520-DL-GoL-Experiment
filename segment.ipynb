{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1862,"status":"ok","timestamp":1732119560703,"user":{"displayName":"Nicholas Bosley","userId":"06594136900126197273"},"user_tz":300},"id":"RZzEbCCG8Nfz","outputId":"fc16cc7c-fd38-402c-9b3d-2c67e6716fcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","['constants.py', 'catagolue.parquet', 'world_catagolue.parquet', 'image_classifier.py', 'generate_worlds.py', 'segment.ipynb', '__pycache__']\n"]}],"source":["# For running in colab\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","import sys\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment, it should be under CS354-Assignments-2022/netid-A1\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'CS6540-F24/Project' # change this directory to yours\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","sys.path.append(GOOGLE_DRIVE_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qG_Gf9fzIExo"},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from tqdm import trange"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110546,"status":"ok","timestamp":1732122019633,"user":{"displayName":"Nicholas Bosley","userId":"06594136900126197273"},"user_tz":300},"id":"3AV5qRNS5xxU","outputId":"2d1f3ae0-e285-4984-bca5-09a7f0b97eec"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["from generate_worlds import load_world_df, truncate_labels, visualize_world\n","from pathlib import Path\n","import polars as pl\n","\n","INPUT_PATH = Path('/content/drive/MyDrive/'+GOOGLE_DRIVE_PATH_AFTER_MYDRIVE+'/world_catagolue.parquet')\n","CATEGORY_COUNT = 4\n","# Load in the data into trainset and testset\n","def load_and_process_data():\n","  if INPUT_PATH.exists():\n","      df = pl.read_parquet(INPUT_PATH)\n","  else:\n","      print('No worlds file')\n","      return None\n","\n","  worlds = []\n","  labels = []\n","\n","  for idx, row in enumerate(df.rows(named=True)):\n","    if idx % 2 == 0:\n","      print(f'{idx}/{len(df)}', end='')\n","    else:\n","      print('',end='\\r')\n","\n","    world = row['world pattern']\n","    label = row['label']\n","\n","    new_label = truncate_labels(world, label, pad_size = 2)\n","\n","    worlds.append(world)\n","    labels.append(new_label)\n","\n","\n","  return worlds, labels\n","\n","ws, ls = load_and_process_data()"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"M1rfKqVscGk-","executionInfo":{"status":"ok","timestamp":1732122817464,"user_tz":300,"elapsed":2467,"user":{"displayName":"Nicholas Bosley","userId":"06594136900126197273"}},"outputId":"00a88043-b84e-4f4f-f3dc-ce290b3cd2cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([700, 4, 64, 64])"]},"metadata":{},"execution_count":74},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Load in the training and testing data into distinct tensors\n","\n","# Maybe get to  transforms later\n","# import torchvision.transforms as transforms\n","\n","train_data = torch.Tensor(ws[0:700])\n","train_labels = torch.Tensor(ls[0:700])\n","\n","test_data = torch.Tensor(ws[700:])\n","test_labels = torch.Tensor(ls[700:])\n","\n","\n","d = train_data[10]\n","l = train_labels[10]\n","visualize_world(d, l)\n","\n","train_labels.shape"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"lyr9JtWB73DX","executionInfo":{"status":"ok","timestamp":1732122970073,"user_tz":300,"elapsed":543,"user":{"displayName":"Nicholas Bosley","userId":"06594136900126197273"}}},"outputs":[],"source":["from pathlib import Path\n","import warnings\n","\n","\n","# Torch fires this warning on every call to load_state_dict()\n","warnings.filterwarnings('ignore', category=UserWarning, message='TypedStorage is deprecated')\n","\n","# Code adapted from the work done by user 'Nikdenof' from Medium\n","# https://medium.com/@nikdenof/segnet-from-scratch-using-pytorch-3fe9b4527239\n","\n","# Which is in turn based on the paper\n","# SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\n","# https://arxiv.org/pdf/1511.00561\n","class ConvBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n","    super(ConvBlock, self).__init__()\n","    self.stack = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU()\n","    )\n","\n","  def forward(self, x):\n","    return self.stack(x)\n","\n","class EncoderBlock(nn.Module):\n","  # Creates an encoder block with [depth] convolution layers\n","  def __init__(self, in_channels, out_channels, depth=2, kernel_size=3, padding=1):\n","    super(EncoderBlock, self).__init__()\n","    self.layers = nn.ModuleList()\n","    for i in range(depth):\n","      self.layers.append(ConvBlock(in_channels, out_channels, kernel_size, padding))\n","      in_channels = out_channels\n","    self.pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n","\n","  def forward(self, x):\n","    for layer in self.layers:\n","      x = layer(x)\n","    x, ind = self.pool(x)\n","    return x, ind\n","\n","class DecoderBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels, depth=2, kernel_size=3, padding=1, classification=False):\n","    super(DecoderBlock, self).__init__()\n","    self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n","    self.layers = nn.ModuleList()\n","    # Recall that this is the decoder, so out_channels > in_channels\n","    for i in range(depth):\n","      if i == depth - 1:\n","        if classification:\n","          # Don't need BN or ReLU on the final layer\n","          self.layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, padding))\n","        else:\n","          # Expand at the final layer of the block\n","          self.layers.append(ConvBlock(in_channels, out_channels, kernel_size, padding))\n","      else:\n","        self.layers.append(ConvBlock(in_channels, in_channels, kernel_size, padding))\n","\n","  def forward(self, x, ind):\n","    x = self.unpool(x, ind)\n","    for layer in self.layers:\n","      x = layer(x)\n","    return x\n","\n","class SegNet(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=1, features=64):\n","        super(SegNet, self).__init__()\n","\n","        # Encoder\n","        self.enc0 = EncoderBlock(in_channels, features)\n","        self.enc1 = EncoderBlock(features, features * 2)\n","        self.enc2 = EncoderBlock(features * 2, features * 4, depth=3)\n","        self.enc3 = EncoderBlock(features * 4, features * 8, depth=3)\n","\n","        # Bottleneck\n","        self.bottleneck_enc = EncoderBlock(features * 8, features * 8, depth=3)\n","        self.bottleneck_dec = DecoderBlock(features * 8, features * 8, depth=3)\n","\n","        # Decoder\n","        self.dec0 = DecoderBlock(features * 8, features * 4, depth=3)\n","        self.dec1 = DecoderBlock(features * 4, features * 2, depth=3)\n","        self.dec2 = DecoderBlock(features * 2, features)\n","        self.dec3 = DecoderBlock(features, out_channels, classification=True) # Final layer classifies\n","\n","    def forward(self, x):\n","        # encoder\n","        e0, ind0 = self.enc0(x)\n","        e1, ind1 = self.enc1(e0)\n","        e2, ind2 = self.enc2(e1)\n","        e3, ind3 = self.enc3(e2)\n","\n","        # bottleneck\n","        b0, indb = self.bottleneck_enc(e3)\n","        b1 = self.bottleneck_dec(b0, indb)\n","\n","        # decoder\n","        d0 = self.dec0(b1, ind3)\n","        d1 = self.dec1(d0, ind2)\n","        d2 = self.dec2(d1, ind1)\n","\n","        # classification layer\n","        output = self.dec3(d2, ind0)\n","        return output"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"9sI4MQKFH8wo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732123191512,"user_tz":300,"elapsed":749,"user":{"displayName":"Nicholas Bosley","userId":"06594136900126197273"}},"outputId":"dbebbdd0-a6e0-412d-87d7-a32b98d0fe9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["# To use GPU, you can set it in the menu \"Runtime\" - > \"change runtime type\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Put the network on the GPU\n","segnet = SegNet(in_channels = 1, out_channels = 4)\n","#segnet = SegNet.to(device)\n","\n","# This likely needs to change to some form of IoU\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.Adam(segnet.parameters(), lr = 0.001)"]},{"cell_type":"code","source":["# train MobileNet here.\n","segnet.train()\n","\n","for epoch in range(10):  # Repeat multiple rounds\n","    for i, (inputs, labels) in enumerate(zip(train_data, train_labels)):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # add your code here ...\n","        optimizer.zero_grad()\n","        output = segnet(inputs)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Output statistics\n","        if i % 100 == 0:\n","            print('Epoch: %d Minibatch: %5d loss: %.3f' %(epoch + 1, i + 1, loss.item()))\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WEnVICn1kv-y","executionInfo":{"status":"error","timestamp":1732123193111,"user_tz":300,"elapsed":254,"user":{"displayName":"Nicholas Bosley","userId":"06594136900126197273"}},"outputId":"87c93f46-974c-41db-8886-9968aa0516f0"},"execution_count":81,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 64]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-759770c3c8e1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# add your code here ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-75-5a5291972588>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0me0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-75-5a5291972588>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-75-5a5291972588>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEncoderBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 64]"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNr5+bCyyygc97aladLBRVb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}